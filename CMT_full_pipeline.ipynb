{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffb6a6d",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "-Extract the gene counts for the whole genome in order to generate the minor allele frequencies for each of the variants\n",
    "<br>\n",
    "-Filter these variants by only those with MAFs < 0.001 (1e-03)\n",
    "<br>\n",
    "-Then generate the gene counts for the CMT diagnosed eid cohort, and merge with the filtered variants, leaving only CMT diagnosed variants with MAF < 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a811f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# downloading plink\n",
    "conda install bioconda::plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx download \"Bulk/Exome sequences/Population level exome OQFE variants, PLINK format - final release/ukb23158_c*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx download \"projects/CMT_NashBio/input_data/cmt_gene_location*.csv\"\n",
    "dx download \"projects/CMT_NashBio/input_data/diagnosed_eid.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2207c",
   "metadata": {},
   "source": [
    "## Generating minor allele frequencies (MAF) for each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7217ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for MAF generation for each variant within CMT gene regions\n",
    "# loading necessary packages\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Load gene location data\n",
    "gene_location = pd.read_csv(\"cmt_gene_locations.csv\")\n",
    "gene_location_x = pd.read_csv(\"cmt_gene_location_x.csv\")\n",
    "\n",
    "# Chromosomes to process\n",
    "ints = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "\n",
    "# loop through chromosomes individually\n",
    "for value in ints:\n",
    "    # create temporary file for just genes within the chromosome being looped through\n",
    "    temp = gene_location[gene_location[\"chrom\"] == value]\n",
    "\n",
    "    # creating the plink query to be run\n",
    "    for _, gene in temp.iterrows():\n",
    "        bfile = f\"ukb23158_c{value}_b0_v1\"\n",
    "        start = int(gene[\"start\"])\n",
    "        end = int(gene[\"end\"])\n",
    "        gene_name = gene[\"gene\"]\n",
    "        out = f\"{gene_name}_out\"\n",
    "\n",
    "        # Step 1: Extracting the region for each INDIVIDUAL GENE - first stage\n",
    "        command1 = [\n",
    "            \"plink\",\n",
    "            \"--bfile\", bfile,\n",
    "            \"--chr\", str(value),\n",
    "            \"--from-bp\", str(start),\n",
    "            \"--to-bp\", str(end),\n",
    "            \"--make-bed\",\n",
    "            \"--out\", out\n",
    "        ]\n",
    "\n",
    "        # Step 2: Calculate variant frequencies\n",
    "        output2 = f\"{gene_name}_freq_out\"\n",
    "        command2 = [\n",
    "            \"plink2\",\n",
    "            \"--bfile\", out,\n",
    "            \"--freq\",\n",
    "            \"--max-maf\", \"0.001\",\n",
    "            \"--out\", output2\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(command1, check=True)\n",
    "            subprocess.run(command2, check=True)\n",
    "            print(f\"Completed rare variant extraction for gene {gene_name} on chromosome {value}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error processing gene {gene_name} on chromosome {value}: {e}\")\n",
    "\n",
    "# running same script but for chromosome X\n",
    "for _, gene in gene_location_x.iterrows():\n",
    "    bfile = f\"ukb23158_cX_b0_v1\"\n",
    "    start = int(gene[\"start\"])\n",
    "    end = int(gene[\"end\"])\n",
    "    out = f\"{gene['gene']}_out\"\n",
    "\n",
    "    command1 = [\n",
    "        \"plink\",\n",
    "        \"--bfile\", bfile,\n",
    "        \"--chr\", \"X\",\n",
    "        \"--from-bp\", str(start),\n",
    "        \"--to-bp\", str(end),\n",
    "        \"--make-bed\",  \n",
    "        \"--out\", out\n",
    "    ]\n",
    "\n",
    "    output2 = f\"{gene['gene']}_freq_out\"\n",
    "    command2 = [\n",
    "        \"plink\",\n",
    "        \"--bfile\", out,\n",
    "        \"--freq\",\n",
    "        \"--max-maf\", \"0.0001\",\n",
    "        \"--out\", output2\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command1, check=True)\n",
    "        subprocess.run(command2, check=True)\n",
    "        print(f\"Completed rare variant extraction for gene {gene} on chromosome X\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing gene {gene} on chromosome X: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e264b58",
   "metadata": {},
   "source": [
    "### Combining all .frq files into a single file\n",
    "filter for MAF < 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Function to read and clean .frq files\n",
    "def read_freq_clean(file):\n",
    "    # Assuming space-separated values with a header\n",
    "    df = pd.read_csv(file, sep=' ', header=0)\n",
    "    return df\n",
    "\n",
    "# Get list of all .frq files in the current directory\n",
    "freq_file_list = glob.glob(\"*.frq\")\n",
    "\n",
    "# Read and combine all .frq files\n",
    "freq_data_list = [read_freq_clean(file) for file in freq_file_list]\n",
    "combined_freq_data = pd.concat(freq_data_list, ignore_index=True)\n",
    "\n",
    "# Filter for MAF < 0.001\n",
    "filtered_freq_data = combined_freq_data[combined_freq_data['MAF'] < 0.001]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e613e",
   "metadata": {},
   "source": [
    "## filtering whole exome sequencing data to only include those diagnosed with CMT\n",
    "Then, extract minor allele calls from each gene region, listed in cmt_gene_locations.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8097cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering whole exome data to only include 192 individuals diagnosed with CMT\n",
    "# then extracting gene regions to identify variants\n",
    "# loading necessary packages\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Load gene location data\n",
    "gene_loc = pd.read_csv(\"cmt_gene_locations.csv\")\n",
    "\n",
    "# Chromosomes to process\n",
    "chromosomes = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "\n",
    "# read eid of those diagnosed with CMT\n",
    "with open(\"diagnosed_eid.txt\", \"r\") as f:\n",
    "    eids_file = f.name\n",
    "\n",
    "# loop through chromosomes individually\n",
    "for chrom in chromosomes:\n",
    "    # generate temporary file for genes filtered by chromosome being looped through\n",
    "    temp = gene_loc[gene_loc[\"chrom\"] == chrom]\n",
    "    \n",
    "    bfile = f\"ukb23158_c{chrom}_b0_v1\"\n",
    "    output1 = f\"chr{chrom}_filtered\"\n",
    "\n",
    "    # generating PLINK query for filtering eids\n",
    "    command1 = [\n",
    "        \"plink\",\n",
    "        \"--bfile\", bfile,\n",
    "        \"--keep\", eids_file,\n",
    "        \"--make-bed\",\n",
    "        \"--out\", output1\n",
    "    ]\n",
    "\n",
    "    # running first query\n",
    "    try:\n",
    "        subprocess.run(command1, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error filtering chromosome {chrom}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # loop through each gene in temporary file to identify variants carried in each gene regions for CMT carriers\n",
    "    for _, gene in temp.iterrows():\n",
    "        start = int(gene[\"start\"])\n",
    "        end = int(gene[\"end\"])\n",
    "        gene_name = gene[\"gene\"]\n",
    "        output2 = f\"{gene_name}_gene\"\n",
    "        # setting out query\n",
    "        command2 = [\n",
    "            \"plink\",\n",
    "            \"--bfile\", output1,\n",
    "            \"--chr\", str(chrom),\n",
    "            \"--from-bp\", str(start),\n",
    "            \"--to-bp\", str(end),\n",
    "            \"--recode\", \"vcf\",\n",
    "            \"--out\", output2\n",
    "        ]\n",
    "\n",
    "        # running query\n",
    "        try:\n",
    "            subprocess.run(command2, check=True)\n",
    "            print(f\"Completed rare variant extraction for gene {gene_name} on chromosome {chrom}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error processing gene {gene_name} on chromosome {chrom}: {e}\")\n",
    "\n",
    "\n",
    "# Load eid data\n",
    "with open(\"diagnosed_eid.txt\", \"r\") as f:\n",
    "    eids_file = f.name\n",
    "\n",
    "# Load gene data for those on the X chromosome\n",
    "gene_loc = pd.read_csv(\"cmt_gene_location_x.csv\")\n",
    "\n",
    "\n",
    "bfile = f\"ukb23158_cX_b0_v1\"\n",
    "output1 = f\"chrX_filtered\"\n",
    "\n",
    "# set out query for X chromosome filtering for gene region\n",
    "command1 = [\n",
    "    \"plink\",\n",
    "    \"--bfile\", bfile,\n",
    "    \"--keep\", eids_file,\n",
    "    \"--make-bed\",\n",
    "    \"--out\", output1\n",
    "]\n",
    "subprocess.run(command1, check=True)\n",
    "for _, gene in gene_loc.iterrows():\n",
    "\n",
    "\n",
    "    start = int(gene[\"start\"])\n",
    "    end = int(gene[\"end\"])\n",
    "    gene_name = gene[\"gene\"]\n",
    "    output2 = f\"{gene_name}_gene\"\n",
    "    # query for filtering gene regions on X chromosome\n",
    "    command2 = [\n",
    "        \"plink\",\n",
    "        \"--bfile\", \"chrX_filtered\",\n",
    "        \"--chr\", \"X\",\n",
    "        \"--from-bp\", str(start),\n",
    "        \"--to-bp\", str(end),\n",
    "        \"--recode\", \"vcf\",\n",
    "        \"--out\", output2\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        \n",
    "        subprocess.run(command2, check=True)\n",
    "        print(f\"Completed rare variant extraction for gene {gene} on chromosome X\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing gene {gene} on chromosome X: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6349a9",
   "metadata": {},
   "source": [
    "### Combining all gene output VCF into a single VCF file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all gene vcf files into a single file for analysis\n",
    "# loading necessary packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def read_vcf(file):\n",
    "    # Read the file line by line to find the header\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Find the line number where the header starts\n",
    "    header_line = next(i for i, line in enumerate(lines) if line.startswith('#CHROM'))\n",
    "    \n",
    "    # Read the VCF from the header line onward\n",
    "    df = pd.read_csv(file, sep='\\t', skiprows=header_line, header=0)\n",
    "    return df\n",
    "\n",
    "# List all VCF files ending with 'gene.vcf'\n",
    "vcf_file_list = glob.glob(\"*gene.vcf\")\n",
    "\n",
    "# Read and combine all VCF files\n",
    "vcf_data_list = [read_vcf(file) for file in vcf_file_list]\n",
    "gene_vcf_unfiltered = pd.concat(vcf_data_list, ignore_index=True)\n",
    "\n",
    "# filtering vcf to only include variants with MAF < 0.001\n",
    "gene_vcf = pd.merge(gene_vcf_unfiltered, filtered_freq_data, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f40726",
   "metadata": {},
   "source": [
    "### Extract carrier and count data for CMT carrier minor allele calls\n",
    "This data can then be used to construct a list of variants carried by individuals diagnosed with CMT\n",
    "<br>\n",
    "These variants are then extracted from the whole WES cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# extracting carrier and count data for each of the variants identified\n",
    "\n",
    "# function for extraction of carriers per variant\n",
    "def extract_carriers(dataset):\n",
    "    # Convert to DataFrame if not already\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    # Melt the DataFrame: first 8 columns are identifiers, rest are sample genotypes\n",
    "    id_vars = df.columns[:8].tolist()\n",
    "    melted = df.melt(id_vars=id_vars, var_name='sample', value_name='genotype')\n",
    "\n",
    "    # Determine zygosity\n",
    "    def get_zygosity(gt):\n",
    "        if gt in [\"0/1\", \"1/0\"]:\n",
    "            return \"het\"\n",
    "        elif gt == \"1/1\":\n",
    "            return \"hom\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    melted['zygosity'] = melted['genotype'].apply(get_zygosity)\n",
    "\n",
    "    # Filter out rows without zygosity\n",
    "    result = melted[melted['zygosity'].notna()].copy()\n",
    "\n",
    "    # Extract carrier ID (first 7 characters of sample name)\n",
    "    result['carrier'] = result['sample'].str[:7]\n",
    "\n",
    "    # Select and rename columns\n",
    "    result = result[[\n",
    "        df.columns[0],  # chrom\n",
    "        df.columns[1],  # pos\n",
    "        df.columns[2],  # ID\n",
    "        df.columns[3],  # ref\n",
    "        df.columns[4],  # alt\n",
    "        'zygosity',\n",
    "        'carrier'\n",
    "    ]]\n",
    "\n",
    "    return result\n",
    "\n",
    "# generating carrier data using function\n",
    "gene_carriers = extract_carriers(gene_vcf)\n",
    "\n",
    "# generating count data for each variant identified\n",
    "# Step 1: Count zygosity per ID\n",
    "counts = gene_carriers.groupby(['ID', 'zygosity']).size().reset_index(name='Freq')\n",
    "\n",
    "counts_wide = counts.pivot(index='ID', columns='zygosity', values='Freq').reset_index()\n",
    "\n",
    "# set missing values to NA\n",
    "counts_wide = counts_wide.fillna(pd.NA)\n",
    "\n",
    "# Step 4: Rename columns (optional, if needed)\n",
    "counts_wide.columns.name = None  # remove pivot column name\n",
    "counts_wide = counts_wide.rename(columns={'het': 'het', 'hom': 'hom'})\n",
    "\n",
    "# Extract distinct carrier metadata (excluding zygosity and carrier)\n",
    "carrier_info = gene_carriers.drop(columns=['zygosity', 'carrier']).drop_duplicates()\n",
    "final_counts = pd.merge(counts_wide, carrier_info, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241016dd",
   "metadata": {},
   "source": [
    "### Generating text files with the minor allele calls for each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9da2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating chromosome level individual text files\n",
    "# each list the variants found within the chromosome, to be used in --extract command with PLINK\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get unique chromosomes\n",
    "unique_chroms = final_counts['chrom'].unique()\n",
    "\n",
    "# Loop through each chromosome\n",
    "for chromosome in unique_chroms:\n",
    "    # Subset data for this chromosome\n",
    "    chrom_data = final_counts[final_counts['chrom'] == chromosome]\n",
    "\n",
    "    # Select and deduplicate the 'ID' column\n",
    "    df = chrom_data[['ID']].drop_duplicates()\n",
    "\n",
    "    # Write to file without headers and quotes, using ':' as separator\n",
    "    df.to_csv(f\"chr{chromosome}.txt\", index=False, header=False, sep=':', quoting=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f4f11",
   "metadata": {},
   "source": [
    "# Extracting variants from whole population\n",
    "-Generate txt files for each chromosome listing all variants\n",
    "<br>\n",
    "-Use this to extract (--extract) the variants for the entire population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "ints = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "\n",
    "for value in ints:\n",
    "    bfile = f\"ukb23158_c{value}_b0_v1\"\n",
    "    output = f\"chr{value}_out\"\n",
    "    snps = f\"chr{value}.txt\"\n",
    "    command = [\n",
    "        \"plink\",\n",
    "        \"--bfile\", bfile,\n",
    "        \"--extract\", snps,\n",
    "        \"--recode\", \"vcf\",\n",
    "        \"--out\", output\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Completed chromosome {value}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing chromosome {value}: {e}\")\n",
    "\n",
    "\n",
    "bfile = f\"ukb23158_cX_b0_v1\"\n",
    "output = f\"chrX_out\"\n",
    "snps = f\"chr23.txt\"\n",
    "command = [\n",
    "    \"plink\",\n",
    "    \"--bfile\", bfile,\n",
    "    \"--extract\", snps,\n",
    "    \"--recode\", \"vcf\",\n",
    "    \"--out\", output\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"Completed chromosome {value}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error processing chromosome {value}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291240cf",
   "metadata": {},
   "source": [
    "### Combining whole population variant call VCF into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all gene vcf files into a single file for analysis\n",
    "# loading necessary packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# List all VCF files ending with 'gene.vcf'\n",
    "whole_list = glob.glob(\"*gene.vcf\")\n",
    "\n",
    "# Read and combine all VCF files\n",
    "whole_data = [read_vcf(file) for file in whole_list]\n",
    "whole_vcf = pd.concat(whole_data, ignore_index=True)\n",
    "\n",
    "whole_vcf.to_csv(\"whole.vcf\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf154e51",
   "metadata": {},
   "source": [
    "### Code for loading Ensembl's variant effect predictor\n",
    "Used to annotate identified variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install sudo annd other in foreground due to installation order dependencies\n",
    "wget https://www.sudo.ws/dist/sudo-1.9.15p5.tar.gz \\\n",
    "  && tar xf sudo-1.9.15p5.tar.gz \\\n",
    "  && cd sudo-1.9.15p5 \\\n",
    "  && ./configure && make && make install \\\n",
    "  && cd .. && rm -f sudo-1.9.15p5.tar.gz && rm -rf sudo-1.9.15p5\n",
    "\n",
    "# Install build-essential package\n",
    "sudo apt update\n",
    "sudo apt install -y build-essential libmysqlclient-dev\n",
    "\n",
    "# Install Perl modules using cpanminus\n",
    "curl -L https://cpanmin.us | sudo perl - App::cpanminus\n",
    "sudo cpanm Archive::Zip DBI DBD::mysql Bio::Root::Version Bio::DB::HTS\n",
    "\n",
    "# Clone and setup VEP\n",
    "git clone https://github.com/Ensembl/ensembl-vep.git\n",
    "cd ensembl-vep\n",
    "perl INSTALL.pl --AUTO acfp --ASSEMBLY GRCh38 --PLUGINS all --SPECIES homo_sapiens\n",
    "\n",
    "# Download Homo sapiens cache data for VEP\n",
    "curl -O https://ftp.ensembl.org/pub/release-115/variation/indexed_vep_cache/homo_sapiens_vep_115_GRCh38.tar.gz\n",
    "tar xzf homo_sapiens_vep_115_GRCh38.tar.gz\n",
    "rm homo_sapiens_vep_115_GRCh38.tar.gz\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vcf = \"whole.vcf\"\n",
    "output_vcf = \"whole_input.vcf\"\n",
    "\n",
    "with open(input_vcf, \"r\") as infile, open(output_vcf, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        if line.startswith(\"#\"):\n",
    "            # Write header lines unchanged\n",
    "            outfile.write(line)\n",
    "        else:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            if fields[0] == \"23\":\n",
    "                fields[0] = \"X\"\n",
    "            outfile.write(\"\\t\".join(fields) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894642a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Annotate the SCN9A vcf file\n",
    "./ensembl-vep/vep -i ./whole_input.vcf --format vcf --fork 4 --cache --dir_cache ./ensembl-vep --species homo_sapiens --pick --everything --canonical --vcf --buffer_size 100 --force_overwrite -o whole_anno.vcf\n",
    "\n",
    "sed 's/INFO/Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|MANE|MANE_SELECT|MANE_PLUS_CLINICAL|TSL|APPRIS|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|UNIPROT_ISOFORM|GENE_PHENO|SIFT|PolyPhen|DOMAINS|miRNA|HGVS_OFFSET|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|gnomADe_AF|gnomADe_AFR_AF|gnomADe_AMR_AF|gnomADe_ASJ_AF|gnomADe_EAS_AF|gnomADe_FIN_AF|gnomADe_MID_AF|gnomADe_NFE_AF|gnomADe_REMAINING_AF|gnomADe_SAS_AF|gnomADg_AF|gnomADg_AFR_AF|gnomADg_AMI_AF|gnomADg_AMR_AF|gnomADg_ASJ_AF|gnomADg_EAS_AF|gnomADg_FIN_AF|gnomADg_MID_AF|gnomADg_NFE_AF|gnomADg_REMAINING_AF|gnomADg_SAS_AF|MAX_AF|MAX_AF_POPS|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS/g' whole_anno.vcf > whole_anno1.vcf\n",
    "sed 's/|/\\t/g' whole_anno1.vcf > whole_anno_final.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbadba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
