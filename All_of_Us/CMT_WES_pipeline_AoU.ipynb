{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6254375",
   "metadata": {},
   "source": [
    "# Full AoU pipeline\n",
    "This script will:\n",
    "<br>\n",
    "- calculate the MAFs for each variant\n",
    "- filter the sample to those with CMT diagnosis\n",
    "- extract gene regions\n",
    "- output VCF of variant counts and MAF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/CMT_pipeline_1.sh\n",
    "#!/bin/bash\n",
    "set -o pipefail\n",
    "set -o errexit\n",
    "\n",
    "# Make sure plink is executable\n",
    "chmod +x \"${plink}\"\n",
    "\n",
    "# Input variables\n",
    "chrom=\"${chrom}\"\n",
    "bgenfile=\"${bgenfile}\"\n",
    "samplefile=\"${samplefile}\"\n",
    "gene_info=\"${gene_info}\"\n",
    "keep_samples=\"${keep_samples}\"\n",
    "flagged_samples=\"${flagged_samples}\"     # ensure this is set (can be an empty file)\n",
    "outdir=\"${OUTPUT_PATH}/\"\n",
    "mkdir -p \"${outdir}\"\n",
    "\n",
    "# Normalize chrom input and set prefix, enabling split-par automatically for X\n",
    "# Recognizes: 23, X, x, chrX, chr23\n",
    "case \"${chrom}\" in\n",
    "    23|\"X\"|\"x\"|\"chrX\"|\"chr23\")\n",
    "        chrom_norm=\"23\"\n",
    "        prefix=\"chrX\"\n",
    "        splitpar_flag=\"--split-par b38\"    # NO BUILD ARGUMENT, per your request\n",
    "        ;;\n",
    "    *)\n",
    "        # Strip \"chr\" prefix if provided, and handle normal autosomes\n",
    "        chrom_norm=\"${chrom#chr}\"\n",
    "        prefix=\"chr${chrom_norm}\"\n",
    "        splitpar_flag=\"\"\n",
    "        ;;\n",
    "esac\n",
    "\n",
    "echo \"Running gene extraction for ${prefix} (split-par: '${splitpar_flag}')...\"\n",
    "\n",
    "# Step 1: Filter to just the individuals in keep_samples\n",
    "\"${plink}\" --bgen \"${bgenfile}\" ref-first \\\n",
    "    --sample \"${samplefile}\" \\\n",
    "    --keep \"${keep_samples}\" \\\n",
    "    --remove \"${flagged_samples}\" \\\n",
    "    ${splitpar_flag} \\\n",
    "    --make-pgen \\\n",
    "    --out \"${prefix}_filtered\"\n",
    "\n",
    "# Step 2: Extract gene region from the filtered dataset to VCF\n",
    "\"${plink}\" --pfile \"${prefix}_filtered\" \\\n",
    "    --extract range \"${gene_info}\" \\\n",
    "    --export vcf \\\n",
    "    --out \"${prefix}_gene\"\n",
    "\n",
    "# Step 3: Create REF allele file from VCF (no bcftools)\n",
    "grep -v '^#' \"${prefix}_gene.vcf\" | \\\n",
    "awk '{\n",
    "    if ($3 == \".\") {\n",
    "        # Build ID as chrom:pos:REF:ALT\n",
    "        print $1 \":\" $2 \":\" $4 \":\" $5 \"\\t\" $4\n",
    "    } else {\n",
    "        # Use existing ID\n",
    "        print $3 \"\\t\" $4\n",
    "    }\n",
    "}' > \"${prefix}_refalleles.txt\"\n",
    "\n",
    "# Step 4: Save variant IDs\n",
    "\"${plink}\" --vcf \"${prefix}_gene.vcf\" \\\n",
    "    --write-snplist \\\n",
    "    --out \"${prefix}_variants\"\n",
    "\n",
    "# Step 5: Create pfile with correct REF/ALT for filtered dataset\n",
    "\"${plink}\" --pfile \"${prefix}_filtered\" \\\n",
    "    --extract \"${prefix}_variants.snplist\" \\\n",
    "    --ref-allele \"${prefix}_refalleles.txt\" \\\n",
    "    --make-pgen \\\n",
    "    --out \"${prefix}_pfile\"\n",
    "\n",
    "# Step 6: Full frequency data (WHOLE population, not filtered)\n",
    "\"${plink}\" --bgen \"${bgenfile}\" ref-first \\\n",
    "    --sample \"${samplefile}\" \\\n",
    "    --extract \"${prefix}_variants.snplist\" \\\n",
    "    --ref-allele \"${prefix}_refalleles.txt\" \\\n",
    "    ${splitpar_flag} \\\n",
    "    --make-pgen \\\n",
    "    --out \"${prefix}_wholepop_pfile\"\n",
    "\n",
    "\"${plink}\" --pfile \"${prefix}_wholepop_pfile\" \\\n",
    "    --freq \\\n",
    "    --out \"${prefix}_maf\"\n",
    "\n",
    "# Step 7: Export rare variants VCF (filtered to keep_samples)\n",
    "\"${plink}\" --pfile \"${prefix}_pfile\" \\\n",
    "    --export vcf \\\n",
    "    --out \"${prefix}_rare_cmt_variants\"\n",
    "\n",
    "# Step 8: Move outputs to final directory\n",
    "mv \"${prefix}_rare_cmt_variants.vcf\" \"${outdir}/${prefix}_rare_cmt_variants.vcf\"\n",
    "mv \"${prefix}_maf.afreq\" \"${outdir}/${prefix}_maf.afreq\"\n",
    "\n",
    "echo \"Pipeline complete for ${prefix}.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb01c24",
   "metadata": {},
   "source": [
    "## TSV to iterate through chromosomes\n",
    "Lines should be run individually via bash terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing in a bash terminal my tasks file for parallelization\n",
    "cat > CMT_gene_info.tsv << 'EOF'\n",
    "--env chrom\t--input keep_samples\t--input bgenfile\t--input samplefile\t--input gene_info\n",
    "EOF\n",
    "\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    echo -e \"${chr}\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/cmt.ids\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_counts/bgen/chr${chr}_cmt.bgen\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_counts/bgen/chr${chr}_cmt.sample\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/input/chr${chr}.tsv\"\n",
    "  done >> CMT_gene_info.tsv\n",
    "\n",
    "echo -e \"X\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/cmt.ids\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_counts/bgen/chrX_cmt.bgen\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_counts/bgen/chrX_cmt.sample\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/input/chrX.tsv\" >> CMT_gene_info.tsv\n",
    "\n",
    "gsutil -m cp CMT_gene_info.tsv gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "MACHINE_TYPE=\"n2-standard-16\"\n",
    "BASH_SCRIPT=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/CMT_pipeline_1.sh\"\n",
    "TASK_FILE=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/CMT_gene_info_x.tsv\"\n",
    "JOB_NAME=\"cmt_pipeline_I\"\n",
    "\n",
    "dsub \\\n",
    "    --provider google-batch \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --use-private-address \\\n",
    "    --network \"global/networks/network\" \\\n",
    "    --subnetwork \"regions/us-central1/subnetworks/subnetwork\" \\\n",
    "    --image 'marketplace.gcr.io/google/ubuntu1804:latest' \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    --boot-disk-size 3000 \\\n",
    "    --disk-size 1200 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --input plink=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/plink2\" \\\n",
    "    --input flagged_samples=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/als/plink_qc/flagged_samples.fam.ids\" \\\n",
    "    --tasks \"${TASK_FILE}\" \\\n",
    "    --output-recursive OUTPUT_PATH=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_regions/pipeline_out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfcf75",
   "metadata": {},
   "source": [
    "## Downloading and combining VCFs in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b480dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/gene_regions/pipeline_out/*.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56519a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all gene vcf files into a single file for analysis\n",
    "# loading necessary packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def read_vcf(file):\n",
    "    # Read the file line by line to find the header\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Find the line number where the header starts\n",
    "    header_line = next(i for i, line in enumerate(lines) if line.startswith('#CHROM'))\n",
    "    \n",
    "    # Read the VCF from the header line onward\n",
    "    df = pd.read_csv(file, sep='\\t', skiprows=header_line, header=0)\n",
    "    return df\n",
    "\n",
    "# List all VCF files ending with 'gene.vcf'\n",
    "vcf_file_list = glob.glob(\"*gene.vcf\")\n",
    "\n",
    "# Read and combine all VCF files\n",
    "vcf_data_list = [read_vcf(file) for file in vcf_file_list]\n",
    "gene_vcf_unfiltered = pd.concat(vcf_data_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87fe0f",
   "metadata": {},
   "source": [
    "## Downloading and combining afreq files in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Function to read and clean .frq files\n",
    "def read_freq_clean(file):\n",
    "    # Assuming space-separated values with a header\n",
    "    df = pd.read_csv(file, sep='\\t', header=0)\n",
    "    return df\n",
    "\n",
    "# Get list of all .frq files in the current directory\n",
    "freq_file_list = glob.glob(\"*.afreq\")\n",
    "\n",
    "# Read and combine all .frq files\n",
    "freq_data_list = [read_freq_clean(file) for file in freq_file_list]\n",
    "freq = pd.concat(freq_data_list, ignore_index=True)\n",
    "freq_filtered = freq[freq[\"ALT_FREQS\"] < 0.001]\n",
    "freq_subset = freq_filtered[[\"ID\"]]\n",
    "\n",
    "gene_vcf = pd.merge(gene_vcf_unfiltered, freq_subset, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_vcf.to_csv(\"variants_raw.vcf\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf3580",
   "metadata": {},
   "source": [
    "# Annotation\n",
    "Pipeline using Ensembl's VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vcf = \"variants_raw.vcf\"\n",
    "output_vcf = \"variants_input.vcf\"\n",
    "\n",
    "with open(input_vcf, \"r\") as infile, open(output_vcf, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        if line.startswith(\"#\"):\n",
    "            # Write header lines unchanged\n",
    "            outfile.write(line)\n",
    "        else:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            if fields[0] == \"23\":\n",
    "                fields[0] = \"X\"\n",
    "            outfile.write(\"\\t\".join(fields) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53719dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/Ensembl/ensembl-vep.git\n",
    "cd ensembl-vep\n",
    "git checkout release/115\n",
    "mkdir -p .vep\n",
    "curl -O https://ftp.ensembl.org/pub/release-115/variation/indexed_vep_cache/homo_sapiens_vep_115_GRCh38.tar.gz\n",
    "tar xzf homo_sapiens_vep_115_GRCh38.tar.gz -C .vep\n",
    "perl INSTALL.pl\n",
    "wget ftp://ftp.ensembl.org/pub/release-108/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\n",
    "gunzip Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ensembl-vep/\n",
    "perl ./vep \\\n",
    "  --cache \\\n",
    "  --offline \\\n",
    "  --dir_cache .vep \\\n",
    "  --assembly GRCh38 \\\n",
    "  --species homo_sapiens \\\n",
    "  --fasta ./Homo_sapiens.GRCh38.dna.primary_assembly.fa \\\n",
    "  --input_file ../variants_input.vcf \\\n",
    "  --output_file ../variants_out.vcf 2> debug.log \\\n",
    "  --vcf \\\n",
    "  --pick \\\n",
    "  --everything \\\n",
    "  --canonical \\\n",
    "  --force_overwrite \\\n",
    "  --verbose \\\n",
    "  --fork 8 \\\n",
    "  --buffer_size 5000\n",
    "\n",
    "sed 's/INFO/Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|MANE|MANE_SELECT|MANE_PLUS_CLINICAL|TSL|APPRIS|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|UNIPROT_ISOFORM|GENE_PHENO|SIFT|PolyPhen|DOMAINS|miRNA|HGVS_OFFSET|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|gnomADe_AF|gnomADe_AFR_AF|gnomADe_AMR_AF|gnomADe_ASJ_AF|gnomADe_EAS_AF|gnomADe_FIN_AF|gnomADe_MID_AF|gnomADe_NFE_AF|gnomADe_REMAINING_AF|gnomADe_SAS_AF|gnomADg_AF|gnomADg_AFR_AF|gnomADg_AMI_AF|gnomADg_AMR_AF|gnomADg_ASJ_AF|gnomADg_EAS_AF|gnomADg_FIN_AF|gnomADg_MID_AF|gnomADg_NFE_AF|gnomADg_REMAINING_AF|gnomADg_SAS_AF|MAX_AF|MAX_AF_POPS|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS/g' variants_out.vcf > variants_out1.vcf\n",
    "sed 's/|/\\t/g' variants_out1.vcf > variants_anno.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4095d",
   "metadata": {},
   "source": [
    "# Variant Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/CMT_variant_extraction.sh\n",
    "#!/bin/bash\n",
    "set -o pipefail\n",
    "set -o errexit\n",
    "\n",
    "# Make sure plink is executable\n",
    "chmod +x \"${plink}\"\n",
    "\n",
    "# Input variables\n",
    "chrom=\"${chrom}\"\n",
    "bgenfile=\"${bgenfile}\"\n",
    "samplefile=\"${samplefile}\"\n",
    "variants=\"${variants}\"\n",
    "keep_samples=\"${keep_samples}\"\n",
    "flagged_samples=\"${flagged_samples}\"\n",
    "outdir=\"${OUTPUT_PATH}/\"\n",
    "mkdir -p \"${outdir}\"\n",
    "\n",
    "\"${plink}\" --bgen \"${bgenfile}\" ref-first \\\n",
    "    --sample \"${samplefile}\" \\\n",
    "    --remove \"${flagged_samples}\" \\\n",
    "    --extract \"${variants}\" \\\n",
    "    --export vcf \\\n",
    "    --out \"${prefix}_full\"\n",
    "\n",
    "# Step 8: Move outputs to final directory\n",
    "mv \"${prefix}_full.vcf\" \"${outdir}/${prefix}_full.vcf\"\n",
    "\n",
    "echo \"Pipeline complete for ${prefix}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing in a bash terminal my tasks file for parallelization\n",
    "cat > variant_extraction.tsv << 'EOF'\n",
    "--env chrom\t--input bgenfile\t--input samplefile\t--input variants\n",
    "EOF\n",
    "\n",
    "\n",
    "for chr in 1 2 3 5 10 12 14 15 19 22; do\n",
    "    echo -e \"${chr}\\t\\\n",
    "gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/bgen/chr${chr}.bgen\\t\\\n",
    "gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/bgen/chr${chr}.sample\\t\\\n",
    "gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/summary/variant_files/chr${chr}variants.txt\"\n",
    "  done >> variant_extraction.tsv\n",
    "\n",
    "\n",
    "gsutil -m cp variant_extraction.tsv gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0362d",
   "metadata": {},
   "source": [
    "# CNV calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/CNV_filtering.sh\n",
    "#!/bin/bash\n",
    "set -euo pipefail\n",
    "\n",
    "outdir=\"${OUTPUT_PATH}/\"\n",
    "mkdir -p \"${outdir}\"\n",
    "\n",
    "vcf=\"${VCF_FILE}\"\n",
    "outvcf=\"${outdir}/chr17_dup_filtered.vcf\"\n",
    "\n",
    "start=14100000\n",
    "end=15700000\n",
    "minlen=1000000  # minimum SV length in bp\n",
    "\n",
    "# If compressed, decompress; otherwise read directly\n",
    "if [[ \"$vcf\" == *.gz ]]; then\n",
    "    gunzip -c \"$vcf\"\n",
    "else\n",
    "    cat \"$vcf\"\n",
    "fi | awk -v start=\"$start\" -v end=\"$end\" -v minlen=\"$minlen\" '\n",
    "BEGIN { OFS=\"\\t\" }\n",
    "/^#/ { print; next }\n",
    "{\n",
    "    # Manually extract first 8 fields without splitting the whole line\n",
    "    line = $0\n",
    "    n = split(line, arr, \"\\t\")\n",
    "    # arr[1]..arr[8] are CHROM..INFO, arr[9]..arr[n] are genotype/sample columns\n",
    "\n",
    "    # Parse INFO field (arr[8])\n",
    "    endpos = -1\n",
    "    m = split(arr[8], info_fields, \";\")\n",
    "    for (i=1; i<=m; i++) {\n",
    "        if (info_fields[i] ~ /^END=/) {\n",
    "            endpos = substr(info_fields[i], 5) + 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (endpos > 0) {\n",
    "        svlen = endpos - arr[2]\n",
    "        if (arr[5] == \"<DUP>\" && arr[2] >= start && endpos >= start && endpos <= end && svlen > minlen) {\n",
    "            print line\n",
    "        }\n",
    "    }\n",
    "}\n",
    "' > \"$outvcf\"\n",
    "\n",
    "echo \"âœ… Filtered VCF written to $outvcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp /home/jupyter/CNV_filtering.sh gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "MACHINE_TYPE=\"n2-standard-16\"\n",
    "BASH_SCRIPT=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/scripts/CNV_filtering.sh\"\n",
    "JOB_NAME=\"cnv_filtering\"\n",
    "VCF_PATH=\"gs://fc-aou-datasets-controlled/v8/wgs/short_read/structural_variants/vcf/full/AoU_srWGS_SV.v8.chr17.vcf.gz\"\n",
    "\n",
    "dsub \\\n",
    "    --provider google-batch \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --use-private-address \\\n",
    "    --network \"global/networks/network\" \\\n",
    "    --subnetwork \"regions/us-central1/subnetworks/subnetwork\" \\\n",
    "    --image 'marketplace.gcr.io/google/ubuntu1804:latest' \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    --boot-disk-size 3000 \\\n",
    "    --disk-size 1200 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --input VCF_FILE=\"${VCF_PATH}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --output-recursive OUTPUT_PATH=\"gs://fc-secure-1ee5bf43-0b6b-4164-a355-ff45dfe2ae3a/data/cmt/counts/pmp22/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
